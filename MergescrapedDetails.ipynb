{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Avg Price for different types of homes from Trulia.com and Merging city demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing all the required packages \n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#selenium packages\n",
    "from selenium import webdriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "def stripFun(x):\n",
    "    x=x.strip().split(\"(\")[0]\n",
    "    return x.strip()\n",
    "\n",
    "#Settings required to be in incognito mode\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--incognito')\n",
    "baseUrl=\"https://www.trulia.com\"\n",
    "\n",
    "#Instantiating the chromeDriver . Need explicit installation of selenium and Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(baseUrl)\n",
    "time.sleep(5)\n",
    "\n",
    "#Defining the cities List.Will be using these cities to query the website and get the details\n",
    "citiesList=[\"San Jose, CA\",\"Milpitas, CA\",\"Fremont, CA\",\"Hayward, CA\",\"Castro Valley, CA\",\n",
    "            \"Berkeley, CA\",\"Oakland, CA\",\"Dublin, CA\",\"San Ramon, CA\",\n",
    "            \"Danville, CA\",\"Union City, CA\",\"Palo Alto, CA\",\"Santa Clara, CA\",\n",
    "            \"Cupertino, CA\",\"San Mateo, CA\",\"Burlingame, CA\",\"Pleasanton, CA\",\"Newark, CA\",\n",
    "            \"Concord, CA\",\"Walnut Creek, CA\",\"Santa Cruz, CA\",\"Half Moon Bay, CA\"]\n",
    "\n",
    "#Dictionary to hold values for each City\n",
    "priceDict={}\n",
    "#Parent loop tp iterate over cities\n",
    "try:\n",
    "    for j in  range(0,len(citiesList)-21):\n",
    "        city=str(citiesList[j].split(\",\")[0]).strip().replace(\" \",\"_\")\n",
    "        state=str(citiesList[j].split(\",\")[1]).strip()\n",
    "        element=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH, \"//input[@data-testid='location-search-input']\")))\n",
    "        try:\n",
    "            element.click()\n",
    "            element.send_keys(Keys.CONTROL + \"a\");\n",
    "            time.sleep(3)\n",
    "            element.send_keys(Keys.DELETE);\n",
    "            #Sending the city value here. This action will populate the search bar of the website with the given value\n",
    "            element.send_keys(citiesList[j])\n",
    "            \n",
    "            #Trigerring the click event on the Search button\n",
    "            driver.find_element_by_xpath(\"//div[@data-testid='location-search-button']\").click()\n",
    "            time.sleep(10)\n",
    "        except:\n",
    "            print(\"Exception in getting Search Box\")\n",
    "            driver.get(baseUrl+\"/\"+state+\"/\"+city+\"/\");\n",
    "            times.sleep(10)\n",
    "        \n",
    "        #Following code triggers the scroll event so that dynamic HTML could be updated\n",
    "        element = driver.find_element_by_xpath(\"//*[@id='resultsColumn']/nav\")\n",
    "        driver.execute_script(\"return arguments[0].scrollIntoView(true);\", element)\n",
    "        time.sleep(10)\n",
    "        page_source = driver.page_source\n",
    "        soup =  BeautifulSoup(page_source,'lxml')\n",
    "       \n",
    "       #Check if dynamic HTML get created;in case it goes to exception, reload the page and repeat the same\n",
    "        try:\n",
    "            reviewEle2=WebDriverWait(driver,15).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='resultsColumn']/div[3]/div/div/div[1]/div/div[2]\")))\n",
    "          \n",
    "        except:\n",
    "            print(\"Inside exception1\")\n",
    "            driver.get(baseUrl+\"/\"+state+\"/\"+city+\"/\");\n",
    "            time.sleep(10)\n",
    "            element = driver.find_element_by_xpath(\"//*[@id='resultsColumn']/nav\")\n",
    "            driver.execute_script(\"return arguments[0].scrollIntoView(true);\", element)\n",
    "            time.sleep(10)\n",
    "            \n",
    "        #Getting Affordibiility range values in each city\n",
    "        try:\n",
    "            div1 = soup.find('h3', text = re.compile('Affordability of Living')).find_parent('div').find_next_sibling('div')\n",
    "            avgHomeValue=div1.contents[0].get_text()\n",
    "            div2=div1.find_next_sibling('div')\n",
    "            avgValueperUnit=div2.contents[0].get_text()\n",
    "        except:\n",
    "            print(\"Inside exception2\")\n",
    "            priceInfo['AvgHomePrice']=None\n",
    "            priceInfo['AvgPricePerUnit']=None\n",
    "            \n",
    "        \n",
    "        #Get avg price of 1 bedroom,2 bedroom ,3 bedroom ,4 bedroom houses over the last month for each city\n",
    "        tables=pd.read_html(page_source)\n",
    "        \n",
    "        #Transpose the table and get the details\n",
    "        priceInfo=tables[0].transpose()\n",
    "        priceInfo.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "        #Clean the column Names\n",
    "        priceInfo.iloc[0]=priceInfo.iloc[0].apply(stripFun)\n",
    "        priceInfo.columns=priceInfo.iloc[0]\n",
    "        \n",
    "        #Remove the second row\n",
    "        priceInfo=priceInfo[1:]\n",
    "        colList=[\"2 bedrooms\",\"3 bedrooms\",\"4 bedrooms\",\"1 bedroom\"]\n",
    "        for i in colList:\n",
    "            if i not in priceInfo.columns.to_list():\n",
    "                priceInfo[i]=None\n",
    "            else:\n",
    "                pass\n",
    "        priceInfo['AvgHomePrice']=avgHomeValue\n",
    "        priceInfo['AvgPricePerUnit']=avgValueperUnit\n",
    "        priceInfo['City']=city\n",
    "        priceDict[city]=priceInfo\n",
    "    #CLose the driver at the end of loop\n",
    "    driver.quit()\n",
    "       \n",
    "    print(priceDict)\n",
    "except:\n",
    "    print(\"Exception\",Exception.with_traceback())\n",
    "    driver.quit()\n",
    "    \n",
    "    \n",
    "#Merging all the city details into single Dataframe and writing it t the csv file\n",
    "        \n",
    "cityHousePricedf=pd.concat(list(priceDict.values()),ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the dataset and writing to the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanCityDataset(cityHousePricedf):\n",
    "    colList=list(cityHousePricedf.columns)\n",
    "    cityHousePricedf['City']=cityHousePricedf['City'].apply(lambda x:str(x).replace(\"_\",\"\"))\n",
    "    #Clean Avg Home price and Avg PricePerUnit\n",
    "    cityHousePricedf['AvgHomePrice']=cityHousePricedf['AvgHomePrice'].apply(lambda x:re.sub(r'[^\\d.]+', '', str(x)))\n",
    "    #Clean BPovertyLine\n",
    "    cityHousePricedf['AvgPricePerUnit']=cityHousePricedf['AvgPricePerUnit'].apply(lambda x:re.sub(r'[^\\d.]+', '', str(x)))\n",
    "    for i in colList:\n",
    "        cityHousePricedf[i]=cityHousePricedf[i].apply(lambda x:str(x).strip(\"$\").replace(',',''))\n",
    "    return cityHousePricedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityHousePricedf=cleanCityDataset(cityHousePricedf)\n",
    "cityHousePricedf.to_csv(\"AvgPricePerCity.csv\",index=False)\n",
    "cityHousePricedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Merge CrimeIndex information to this file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data collected from above scraping process\n",
    "cityHousePricedf=pd.read_csv(\"AvgPricePerCity.csv\")\n",
    "\n",
    "#CrimeDetailsperCity.csv contains Crime Index information for each city\n",
    "cityCrimeIndexdf=pd.read_csv(\"CrimeDetailsperCity.csv\")\n",
    "uniqueCities=cityCrimeIndexdf['city'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add CrimeIndes column to the Avg Home Price per City Dataset\n",
    "for i in range(0,len(uniqueCities)):\n",
    "    city=str(uniqueCities[i])\n",
    "    \n",
    "    if(cityCrimeIndexdf[cityCrimeIndexdf['city']==str(city)].size > 0):\n",
    "        cityHousePricedf.loc[cityHousePricedf['City']==city,'CrimeIndex']=cityCrimeIndexdf[cityCrimeIndexdf['city']==city]['crimeIndex'].item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityHousePricedf.to_csv(\"AvgPrice_CrimeDetails.csv\",index=False)\n",
    "cityHousePricedf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
